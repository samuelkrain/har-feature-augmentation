{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIc0x7KJLGhY",
        "outputId": "a0f8ba7d-c9e1-48c5-e43d-fe9589fa7e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connect to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A9kMuVVsbiCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa08f5f-68f7-4787-9c0d-7c4b63e784f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "# Imports, setup and parameters\n",
        "import numpy as np\n",
        "import math\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "tf.get_logger().setLevel('DEBUG')\n",
        "\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/University/L3_Project/HAR/data_processing/uci_data\"\n",
        "\n",
        "## CNN parameters\n",
        "\n",
        "segment_size = 128\n",
        "num_input_channels = 6\n",
        "\n",
        "num_training_iterations = 200\n",
        "batch_size = 200\n",
        "\n",
        "l2_reg = 5e-4\n",
        "learning_rate = 5e-4\n",
        "dropout_rate = 0.05\n",
        "\n",
        "n_filters = 2\n",
        "filters_size = 2\n",
        "n_hidden = 8\n",
        "n_classes = 6\n",
        "id = \"b1\"; # Used to uniquely identify model\n",
        "\n",
        "name_fzip = \"a\"+str(id)+\"_\"+str(n_filters)+\"_\"+str(filters_size)+\"_\"+str(n_hidden)+\".zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOGRQqsgBatZ",
        "outputId": "009dafb3-f45f-4912-dfff-cf6391cfe7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading UCI dataset...\n",
            "Dataset was uploaded\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Load the dataset\n",
        "\n",
        "print('Loading UCI dataset...')\n",
        "\n",
        "# Read training data\n",
        "\n",
        "# Modified paths for Drive\n",
        "fa = open(f\"{file_path}/all_data.csv\")\n",
        "ff = open(f\"{file_path}/features.csv\")\n",
        "\n",
        "data_train = np.loadtxt(fname = fa, delimiter = ',')\n",
        "features = np.loadtxt(fname = ff, delimiter = ',')\n",
        "\n",
        "fa.close(); ff.close()\n",
        "\n",
        "# Reading validation data\n",
        "\n",
        "fa = open(f\"{file_path}/all_data_val.csv\")\n",
        "ff = open(f\"{file_path}/val_features.csv\")\n",
        "\n",
        "data_val = np.loadtxt(fname = fa, delimiter = ',')\n",
        "features_val = np.loadtxt(fname = ff, delimiter = ',')\n",
        "\n",
        "fa.close(); ff.close()\n",
        "\n",
        "# Reading test data\n",
        "\n",
        "fa = open(f\"{file_path}/all_data_test.csv\")\n",
        "ff = open(f\"{file_path}/test_features.csv\")\n",
        "\n",
        "data_test = np.loadtxt(fname = fa, delimiter = ',')\n",
        "features_test = np.loadtxt(fname = ff, delimiter = ',')\n",
        "\n",
        "fa.close(); ff.close()\n",
        "\n",
        "# Reading labels\n",
        "#   Training labels\n",
        "fa = open(f\"{file_path}/answers.csv\")\n",
        "labels_train = np.loadtxt(fname = fa, delimiter = ',')\n",
        "fa.close()\n",
        "\n",
        "#   Validation labels\n",
        "fa = open(f\"{file_path}/answers_val.csv\")\n",
        "labels_val = np.loadtxt(fname = fa, delimiter = ',')\n",
        "fa.close()\n",
        "\n",
        "#   Test labels\n",
        "fa = open(f\"{file_path}/answers_test.csv\")\n",
        "labels_test = np.loadtxt(fname = fa, delimiter = ',')\n",
        "fa.close()\n",
        "\n",
        "train_size = data_train.shape[0]\n",
        "val_size = data_val.shape[0]\n",
        "test_size = data_test.shape[0]\n",
        "num_features = features.shape[1]\n",
        "\n",
        "data_val = np.reshape(data_val, [data_val.shape[0], segment_size * num_input_channels])\n",
        "labels_val = np.reshape(labels_val, [labels_val.shape[0], n_classes])\n",
        "features_val = np.reshape(features_val, [features_val.shape[0], num_features])\n",
        "labels_val_max = np.expand_dims(np.argmax(labels_val,axis=1),axis=1)\n",
        "\n",
        "data_test = np.reshape(data_test, [data_test.shape[0], segment_size * num_input_channels])\n",
        "labels_test = np.reshape(labels_test, [labels_test.shape[0], n_classes])\n",
        "features_test = np.reshape(features_test, [features_test.shape[0], num_features])\n",
        "labels_test_max = np.expand_dims(np.argmax(labels_test,axis=1),axis=1)\n",
        "\n",
        "\n",
        "print(\"Dataset was uploaded\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b9dam1hv12Oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f96ced-161e-4956-cc56-9f1b9389c242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nano transmission file generated\n"
          ]
        }
      ],
      "source": [
        "# Create file with data segments and corresponding features for transmission to Nano\n",
        "data_combined = np.concatenate((data_test,features_test,labels_test_max),axis=1)\n",
        "\n",
        "# Specifying the file path\n",
        "file_path = 'data_combined.csv'\n",
        "\n",
        "# Writing the array to the CSV file\n",
        "np.savetxt(file_path, data_combined, delimiter=',', fmt='%3.4g')\n",
        "\n",
        "with zipfile.ZipFile(name_fzip,'a') as myzip:\n",
        "  myzip.write(file_path)\n",
        "\n",
        "print(\"Nano transmission file generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6Oucfbh5KpgW",
        "outputId": "8f8f3d3a-53c1-4cd3-dc77-10352235fe7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating CNN architecture\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1, 128, 6)]          0         []                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 1, 128, 2)            26        ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 1, 32, 2)             0         ['conv1d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 40)]                 0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 104)                  0         ['flatten[0][0]',             \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 104)                  0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 8)                    840       ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 6)                    54        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 920 (3.59 KB)\n",
            "Trainable params: 920 (3.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "38/38 [==============================] - 5s 17ms/step - loss: 6.7335 - accuracy: 0.2011 - sparse_categorical_crossentropy: 6.7260 - val_loss: 3.5798 - val_accuracy: 0.2227 - val_sparse_categorical_crossentropy: 3.5723 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 2.7193 - accuracy: 0.1915 - sparse_categorical_crossentropy: 2.7118 - val_loss: 2.1168 - val_accuracy: 0.1749 - val_sparse_categorical_crossentropy: 2.1093 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 2.0185 - accuracy: 0.1753 - sparse_categorical_crossentropy: 2.0110 - val_loss: 1.9375 - val_accuracy: 0.1649 - val_sparse_categorical_crossentropy: 1.9301 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.8921 - accuracy: 0.1772 - sparse_categorical_crossentropy: 1.8847 - val_loss: 1.8705 - val_accuracy: 0.1564 - val_sparse_categorical_crossentropy: 1.8631 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.8208 - accuracy: 0.1834 - sparse_categorical_crossentropy: 1.8134 - val_loss: 1.7968 - val_accuracy: 0.1572 - val_sparse_categorical_crossentropy: 1.7894 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.7220 - accuracy: 0.2518 - sparse_categorical_crossentropy: 1.7145 - val_loss: 1.6735 - val_accuracy: 0.2689 - val_sparse_categorical_crossentropy: 1.6657 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.6106 - accuracy: 0.3215 - sparse_categorical_crossentropy: 1.6026 - val_loss: 1.5829 - val_accuracy: 0.3274 - val_sparse_categorical_crossentropy: 1.5747 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.5359 - accuracy: 0.3467 - sparse_categorical_crossentropy: 1.5275 - val_loss: 1.5364 - val_accuracy: 0.3436 - val_sparse_categorical_crossentropy: 1.5279 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.4880 - accuracy: 0.3640 - sparse_categorical_crossentropy: 1.4793 - val_loss: 1.4809 - val_accuracy: 0.3436 - val_sparse_categorical_crossentropy: 1.4720 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.4414 - accuracy: 0.3621 - sparse_categorical_crossentropy: 1.4324 - val_loss: 1.4475 - val_accuracy: 0.3428 - val_sparse_categorical_crossentropy: 1.4383 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.4033 - accuracy: 0.3602 - sparse_categorical_crossentropy: 1.3939 - val_loss: 1.4132 - val_accuracy: 0.3475 - val_sparse_categorical_crossentropy: 1.4037 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.3744 - accuracy: 0.3658 - sparse_categorical_crossentropy: 1.3648 - val_loss: 1.3829 - val_accuracy: 0.3498 - val_sparse_categorical_crossentropy: 1.3731 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 1.3401 - accuracy: 0.3729 - sparse_categorical_crossentropy: 1.3303 - val_loss: 1.3556 - val_accuracy: 0.3544 - val_sparse_categorical_crossentropy: 1.3456 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.3179 - accuracy: 0.3763 - sparse_categorical_crossentropy: 1.3078 - val_loss: 1.3274 - val_accuracy: 0.3613 - val_sparse_categorical_crossentropy: 1.3172 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.2946 - accuracy: 0.3806 - sparse_categorical_crossentropy: 1.2843 - val_loss: 1.3069 - val_accuracy: 0.3567 - val_sparse_categorical_crossentropy: 1.2966 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.2635 - accuracy: 0.3870 - sparse_categorical_crossentropy: 1.2530 - val_loss: 1.2768 - val_accuracy: 0.3729 - val_sparse_categorical_crossentropy: 1.2663 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.2410 - accuracy: 0.3985 - sparse_categorical_crossentropy: 1.2304 - val_loss: 1.2491 - val_accuracy: 0.3821 - val_sparse_categorical_crossentropy: 1.2384 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.2049 - accuracy: 0.4211 - sparse_categorical_crossentropy: 1.1941 - val_loss: 1.2124 - val_accuracy: 0.4006 - val_sparse_categorical_crossentropy: 1.2015 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.1614 - accuracy: 0.4384 - sparse_categorical_crossentropy: 1.1504 - val_loss: 1.1786 - val_accuracy: 0.4268 - val_sparse_categorical_crossentropy: 1.1675 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 1.1156 - accuracy: 0.4688 - sparse_categorical_crossentropy: 1.1043 - val_loss: 1.1214 - val_accuracy: 0.4669 - val_sparse_categorical_crossentropy: 1.1101 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 1.0734 - accuracy: 0.4937 - sparse_categorical_crossentropy: 1.0620 - val_loss: 1.0837 - val_accuracy: 0.4861 - val_sparse_categorical_crossentropy: 1.0722 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 1.0331 - accuracy: 0.5109 - sparse_categorical_crossentropy: 1.0215 - val_loss: 1.0443 - val_accuracy: 0.5223 - val_sparse_categorical_crossentropy: 1.0325 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.9858 - accuracy: 0.5425 - sparse_categorical_crossentropy: 0.9740 - val_loss: 0.9961 - val_accuracy: 0.5578 - val_sparse_categorical_crossentropy: 0.9842 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.9211 - accuracy: 0.5928 - sparse_categorical_crossentropy: 0.9090 - val_loss: 0.9461 - val_accuracy: 0.6079 - val_sparse_categorical_crossentropy: 0.9338 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.8431 - accuracy: 0.6283 - sparse_categorical_crossentropy: 0.8307 - val_loss: 0.8530 - val_accuracy: 0.6294 - val_sparse_categorical_crossentropy: 0.8403 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7374 - accuracy: 0.6832 - sparse_categorical_crossentropy: 0.7245 - val_loss: 0.7862 - val_accuracy: 0.6695 - val_sparse_categorical_crossentropy: 0.7732 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.6366 - accuracy: 0.7362 - sparse_categorical_crossentropy: 0.6233 - val_loss: 0.7015 - val_accuracy: 0.7119 - val_sparse_categorical_crossentropy: 0.6880 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.5389 - accuracy: 0.7894 - sparse_categorical_crossentropy: 0.5252 - val_loss: 0.6343 - val_accuracy: 0.7450 - val_sparse_categorical_crossentropy: 0.6203 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.8089 - sparse_categorical_crossentropy: 0.4648 - val_loss: 0.6052 - val_accuracy: 0.7519 - val_sparse_categorical_crossentropy: 0.5908 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.8120 - sparse_categorical_crossentropy: 0.4383 - val_loss: 0.5927 - val_accuracy: 0.7635 - val_sparse_categorical_crossentropy: 0.5779 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.8222 - sparse_categorical_crossentropy: 0.4158 - val_loss: 0.5826 - val_accuracy: 0.7743 - val_sparse_categorical_crossentropy: 0.5675 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8288 - sparse_categorical_crossentropy: 0.4060 - val_loss: 0.5770 - val_accuracy: 0.7797 - val_sparse_categorical_crossentropy: 0.5617 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8411 - sparse_categorical_crossentropy: 0.3864 - val_loss: 0.5741 - val_accuracy: 0.7781 - val_sparse_categorical_crossentropy: 0.5586 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3970 - accuracy: 0.8432 - sparse_categorical_crossentropy: 0.3814 - val_loss: 0.5934 - val_accuracy: 0.7858 - val_sparse_categorical_crossentropy: 0.5779 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8395 - sparse_categorical_crossentropy: 0.3738 - val_loss: 0.5910 - val_accuracy: 0.7773 - val_sparse_categorical_crossentropy: 0.5754 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8461 - sparse_categorical_crossentropy: 0.3661 - val_loss: 0.6114 - val_accuracy: 0.7897 - val_sparse_categorical_crossentropy: 0.5958 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8484 - sparse_categorical_crossentropy: 0.3618 - val_loss: 0.6000 - val_accuracy: 0.7797 - val_sparse_categorical_crossentropy: 0.5844 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8540 - sparse_categorical_crossentropy: 0.3532 - val_loss: 0.6182 - val_accuracy: 0.7881 - val_sparse_categorical_crossentropy: 0.6027 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8512 - sparse_categorical_crossentropy: 0.3471 - val_loss: 0.6330 - val_accuracy: 0.7912 - val_sparse_categorical_crossentropy: 0.6175 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.3648 - accuracy: 0.8508 - sparse_categorical_crossentropy: 0.3494\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8519 - sparse_categorical_crossentropy: 0.3508 - val_loss: 0.6596 - val_accuracy: 0.7874 - val_sparse_categorical_crossentropy: 0.6442 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8526 - sparse_categorical_crossentropy: 0.3478 - val_loss: 0.6397 - val_accuracy: 0.7889 - val_sparse_categorical_crossentropy: 0.6243 - lr: 1.0000e-04\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8573 - sparse_categorical_crossentropy: 0.3393 - val_loss: 0.6382 - val_accuracy: 0.7881 - val_sparse_categorical_crossentropy: 0.6228 - lr: 1.0000e-04\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.8584 - sparse_categorical_crossentropy: 0.3409 - val_loss: 0.6399 - val_accuracy: 0.7912 - val_sparse_categorical_crossentropy: 0.6246 - lr: 1.0000e-04\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.8620 - sparse_categorical_crossentropy: 0.3369 - val_loss: 0.6402 - val_accuracy: 0.7889 - val_sparse_categorical_crossentropy: 0.6248 - lr: 1.0000e-04\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3513 - accuracy: 0.8578 - sparse_categorical_crossentropy: 0.3359 - val_loss: 0.6403 - val_accuracy: 0.7928 - val_sparse_categorical_crossentropy: 0.6249 - lr: 1.0000e-04\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.3550 - accuracy: 0.8594 - sparse_categorical_crossentropy: 0.3397 - val_loss: 0.6413 - val_accuracy: 0.7904 - val_sparse_categorical_crossentropy: 0.6259 - lr: 1.0000e-04\n",
            "Epoch 47/200\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.3525 - accuracy: 0.8624 - sparse_categorical_crossentropy: 0.3372\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8619 - sparse_categorical_crossentropy: 0.3376 - val_loss: 0.6426 - val_accuracy: 0.7920 - val_sparse_categorical_crossentropy: 0.6272 - lr: 1.0000e-04\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8589 - sparse_categorical_crossentropy: 0.3370 - val_loss: 0.6425 - val_accuracy: 0.7920 - val_sparse_categorical_crossentropy: 0.6272 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 1s - loss: 0.4352 - accuracy: 0.8230 - sparse_categorical_crossentropy: 0.4197 - 505ms/epoch - 10ms/step\n",
            "Best model, accuracy: 82.30%\n"
          ]
        }
      ],
      "source": [
        "## Creating CNN\n",
        "\n",
        "print(\"Creating CNN architecture\\n\")\n",
        "\n",
        "# Convolutional and pooling layers\n",
        "input = tf.keras.Input(shape=(1, segment_size, num_input_channels))\n",
        "l_conv = tf.keras.layers.Conv1D(n_filters,filters_size,strides=1,padding='SAME',use_bias=True,activation='relu')(input)\n",
        "l_pool = tf.keras.layers.MaxPooling2D(pool_size=[1,4],strides=[1,4],padding='SAME')(l_conv)\n",
        "\n",
        "# Augmenting data with statistical features\n",
        "\n",
        "# Flattening and feature layers\n",
        "l_flat = tf.keras.layers.Flatten()(l_pool)\n",
        "l_feat = tf.keras.Input(shape=(num_features))\n",
        "\n",
        "# Hidden layer\n",
        "l_hidden = tf.keras.layers.Concatenate()([l_flat,l_feat])\n",
        "\n",
        "# Fully connected layer with dropout and regularizer\n",
        "l_dropout = tf.keras.layers.Dropout(dropout_rate)(l_hidden)\n",
        "reg = tf.keras.regularizers.L2(l2=l2_reg)\n",
        "l_dense = tf.keras.layers.Dense(n_hidden,activation='relu',use_bias=True,kernel_regularizer=reg)(l_dropout)\n",
        "\n",
        "# Prediction/Softmax layer\n",
        "l_predictions = tf.keras.layers.Dense(n_classes,activation='softmax')(l_dense)\n",
        "\n",
        "# Format data for training\n",
        "data_train_reformatted = np.reshape(data_train,newshape=(-1,1,128,6))\n",
        "data_val_reformatted = np.reshape(data_val,newshape=(-1,1,128,6))\n",
        "data_test_reformatted = np.reshape(data_test,newshape=(-1,1,128,6))\n",
        "\n",
        "labels_val_squeezed = np.argmax(labels_val,axis=1)\n",
        "labels_test_squeezed = np.argmax(labels_test,axis=1)\n",
        "labels_train_squeezed = np.argmax(labels_train,axis=1)\n",
        "\n",
        "# Compile model\n",
        "train_model = tf.keras.Model(inputs=[input,l_feat], outputs=l_predictions)\n",
        "train_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy','sparse_categorical_crossentropy'])\n",
        "train_model.summary()\n",
        "\n",
        "# Define training callbacks\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min')\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"har_best.keras\", monitor=\"val_loss\", save_best_only=True)\n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
        "\n",
        "# Train model\n",
        "history = train_model.fit(\n",
        "    x=(data_train_reformatted,features),\n",
        "    y=labels_train_squeezed,\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_training_iterations,\n",
        "    verbose=1,\n",
        "    validation_data=((data_val_reformatted,features_val),labels_val_squeezed),\n",
        "    validation_freq=1,\n",
        "    callbacks=[checkpoint,earlyStopping,reduce_lr_loss]\n",
        ")\n",
        "\n",
        "# Plot the training history\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.plot(epochs,val_accuracy,'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Load best model and check performance\n",
        "model = tf.keras.models.load_model('har_best.keras')\n",
        "metrics = model.evaluate(x=(data_test_reformatted,features_test), y=labels_test_squeezed, verbose=2)\n",
        "acc = metrics[1]\n",
        "print('Best model, accuracy: {:5.2f}%'.format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S0UDrMjW6kvm"
      },
      "outputs": [],
      "source": [
        "# Generate representative dataset for integer quantisation\n",
        "def representative_data_gen():\n",
        "  for i in range(200):\n",
        "    input_data1 = np.float32(np.expand_dims(data_train_reformatted[i],axis=0))\n",
        "    input_data2 = np.float32(np.expand_dims(features[i],axis=0))\n",
        "    yield [input_data1, input_data2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siFc52PWXYuJ",
        "outputId": "0bde1b07-156c-46b1-e1ad-6c226a699400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpy1xjj4dy/assets\n"
          ]
        }
      ],
      "source": [
        "# Convert keras model to unquantised (16-bit floating point) tflite file for comparison\n",
        "tflite_model_name = 'har_model_fp16'  # Will be given .tflite suffix\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model_fp16 = converter.convert()\n",
        "open(tflite_model_name + '.tflite', 'wb').write(tflite_model_fp16)\n",
        "with zipfile.ZipFile(name_fzip,'a') as myzip:\n",
        "  myzip.write(tflite_model_name+'.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFPeMIU-Pzfu",
        "outputId": "4aff9a71-ce5b-45fd-fde1-0c6d260687c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3axhn_51/assets\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  <class 'numpy.uint8'>\n",
            "output:  <class 'numpy.uint8'>\n",
            "[{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([  1,   1, 128,   6], dtype=int32), 'shape_signature': array([ -1,   1, 128,   6], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.026062745600938797, 135), 'quantization_parameters': {'scales': array([0.02606275], dtype=float32), 'zero_points': array([135], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'serving_default_input_2:0', 'index': 1, 'shape': array([ 1, 40], dtype=int32), 'shape_signature': array([-1, 40], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.31901922821998596, 1), 'quantization_parameters': {'scales': array([0.31901923], dtype=float32), 'zero_points': array([1], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "# Convert Keras model to a quantised (8-bit integer) tflite model\n",
        "tflite_model_name = 'har_model_ui8'  # Will be given .tflite suffix\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "tflite_model_ui8 = converter.convert()\n",
        "open(tflite_model_name + '.tflite', 'wb').write(tflite_model_ui8)\n",
        "with zipfile.ZipFile(name_fzip,'a') as myzip:\n",
        "  myzip.write(tflite_model_name+'.tflite')\n",
        "\n",
        "# Check quantised model input/output types\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model_ui8)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)\n",
        "print(interpreter.get_input_details())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2j2VEnedXu3",
        "outputId": "dbd4d3ff-e1dd-4872-9616-da6b7c5ca15b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8352"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Save models as files\n",
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"har_model_fp16.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model_fp16)\n",
        "\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"har_model_ui8.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_ui8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cnmD4BAob59a"
      },
      "outputs": [],
      "source": [
        "# Define necessary variables for test functions\n",
        "test_data_index = 1\n",
        "test_segments = np.float32(data_test_reformatted)\n",
        "test_feature_data = np.float32(features_test)\n",
        "test_labels = labels_test_squeezed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pJx2vZH8Y-o9"
      },
      "outputs": [],
      "source": [
        "# Helper function to run inference on a TFLite model\n",
        "def run_tflite_model(tflite_file, test_data_indices):\n",
        "  global test_segments\n",
        "  global test_feature_data\n",
        "\n",
        "  # Initialize the interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  input2_details = interpreter.get_input_details()[1]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  predictions = np.zeros((len(test_data_indices),), dtype=int)\n",
        "  for i, test_data_index in enumerate(test_data_indices):\n",
        "    test_image = test_segments[test_data_index]\n",
        "    test_features = test_feature_data[test_data_index]\n",
        "\n",
        "    # Check if the input type is quantized, then rescale input data to uint8\n",
        "    if input_details['dtype'] == np.uint8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "      input_scale2, input_zero_point2 = input2_details[\"quantization\"]\n",
        "      test_features = test_features / input_scale2 + input_zero_point2\n",
        "\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "    test_features = np.expand_dims(test_features, axis=0).astype(input2_details[\"dtype\"])\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "    interpreter.set_tensor(input2_details[\"index\"], test_features)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "    predictions[i] = output.argmax()\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jtgI4n_ug7Ap"
      },
      "outputs": [],
      "source": [
        "# Helper function to evaluate a TFLite model on all segments\n",
        "def evaluate_model(tflite_file, model_type):\n",
        "  global test_segments\n",
        "  global test_labels\n",
        "\n",
        "  test_data_indices = range(test_segments.shape[0])\n",
        "  predictions = run_tflite_model(tflite_file, test_data_indices)\n",
        "  # print(predictions[370:390])\n",
        "\n",
        "  counter = 0\n",
        "  for i in range(len(test_segments)):\n",
        "    # Uncomment to print individual inference results to console\n",
        "    # print(str(i+1)+ \" | Match: \" + str(test_labels[i] == predictions[i]) + \" | actual: \" + str(test_labels[i]) + \" | predicted: \" + str(predictions[i]))\n",
        "    if test_labels[i] == predictions[i]:\n",
        "      counter += 1\n",
        "\n",
        "\n",
        "  accuracy = counter * 100 / len(test_segments)\n",
        "\n",
        "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
        "      model_type, accuracy, len(test_segments)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZaoNEPDEcXK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20de29af-565d-43f7-cf1f-8b05a1a39e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model accuracy is 81.4749% (Number of test samples=1695)\n",
            "Float model accuracy is 82.3009% (Number of test samples=1695)\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model accuracy\n",
        "samples_idx = np.random.randint(0,test_segments.shape[0],30)\n",
        "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")\n",
        "evaluate_model(tflite_model_file, model_type=\"Float\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_1raziQq2xUM"
      },
      "outputs": [],
      "source": [
        "# Save one segment of quantised test data as c array for testing\n",
        "input1_details = interpreter.get_input_details()[0]\n",
        "input1_scale, input1_zero_point = input1_details[\"quantization\"]\n",
        "input2_details = interpreter.get_input_details()[1]\n",
        "input2_scale, input2_zero_point = input2_details[\"quantization\"]\n",
        "\n",
        "test_array_data = np.floor(test_segments[0][0] / input1_scale + input1_zero_point).astype(int)\n",
        "test_array_features = np.floor(features_test[0] / input2_scale + input2_zero_point).astype(int)\n",
        "\n",
        "data_filename = 'test_data'\n",
        "c_str = ''\n",
        "c_str += '#include \"' + data_filename + '.h\"\\n\\n'\n",
        "c_str += 'uint8_t test_input1[] = {\\n'\n",
        "\n",
        "# Add values of single test data segment\n",
        "for i,element in enumerate(test_array_data.flat):\n",
        "  if element < 0:\n",
        "    element = 0\n",
        "  elif element > 255:\n",
        "    element = 255\n",
        "  c_str += str(element)\n",
        "  if (i + 1) < len(test_array_data.flat):\n",
        "      c_str += ','\n",
        "  if (i + 1) % 12 == 0:\n",
        "      c_str += '\\n '\n",
        "\n",
        "\n",
        "c_str += '};\\n'\n",
        "c_str += 'const unsigned int test_input1_len = ' + str(len(test_segments[0][0].flatten()))\n",
        "c_str += ';\\n\\n'\n",
        "\n",
        "c_str += 'uint8_t test_input2[] = {\\n'\n",
        "\n",
        "# Add values of corresponding feature vector\n",
        "for i,element in enumerate(test_array_features.flatten()):\n",
        "  if element < 0:\n",
        "    element = 0\n",
        "  elif element > 255:\n",
        "    element = 255\n",
        "  c_str += str(element)\n",
        "  if (i + 1) < len(test_array_features.flatten()):\n",
        "      c_str += ','\n",
        "  if (i + 1) % 12 == 0:\n",
        "      c_str += '\\n '\n",
        "\n",
        "c_str += '};\\n'\n",
        "c_str += 'const unsigned int test_input2_len = ' + str(len(features_test[0].flatten()))\n",
        "c_str += ';\\n\\n'\n",
        "\n",
        "c_str += '// test_label = ' + str(labels_test_squeezed[0]) + ';\\n'\n",
        "\n",
        "with open(data_filename + '.cpp', 'w') as file:\n",
        "  file.write(c_str)\n",
        "with zipfile.ZipFile(name_fzip,'a') as myzip:\n",
        "  myzip.write(data_filename+'.cpp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g6cq4k_cQBtc"
      },
      "outputs": [],
      "source": [
        "# Function: Convert model hex file to C array for MCU\n",
        "def hex_to_c_array(hex_data):\n",
        "  var_name = 'g_model'\n",
        "\n",
        "  c_str = ''\n",
        "\n",
        "  # Create header guard\n",
        "  c_str += '#include \"har_detection_model.h\"\\n\\n'\n",
        "\n",
        "\n",
        "  # Declare C variable\n",
        "  c_str += 'const unsigned char ' + var_name + '[] = {'\n",
        "  hex_array = []\n",
        "  for i, val in enumerate(hex_data) :\n",
        "\n",
        "    # Construct string from hex\n",
        "    hex_str = format(val, '#04x')\n",
        "\n",
        "    # Add formatting so each line stays within 80 characters\n",
        "    if (i + 1) < len(hex_data):\n",
        "      hex_str += ','\n",
        "    if (i + 1) % 12 == 0:\n",
        "      hex_str += '\\n '\n",
        "    hex_array.append(hex_str)\n",
        "\n",
        "  # Add closing brace\n",
        "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
        "\n",
        "    # Add array length at top of file\n",
        "  c_str += 'const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
        "\n",
        "  return c_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WcpmrHn3QDMu"
      },
      "outputs": [],
      "source": [
        "# # Write TFLite model to a C source file\n",
        "c_model_name = 'har_detection_model'\n",
        "with open(c_model_name + '.cpp', 'w') as file:\n",
        "  file.write(hex_to_c_array(tflite_model_ui8))\n",
        "with zipfile.ZipFile(name_fzip,'a') as myzip:\n",
        "  myzip.write(c_model_name+'.cpp')\n",
        "\n",
        "# Alternative method\n",
        "# !xxd -i har_model.tflite > har_detection_model.cpp"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}